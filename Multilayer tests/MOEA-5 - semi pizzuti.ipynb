{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.15 ms\n"
     ]
    }
   ],
   "source": [
    "_2layer_mu0_1_multi = ['mLFR4/2layer_mu0.1_multi_Layer1_Network.txt.txt', 'mLFR4/2layer_mu0.1_multi_Layer2_Network.txt.txt']\n",
    "_2layer_mu0_2_multi = ['mLFR4/2layer_mu0.2_multi_Layer1_Network.txt.txt', 'mLFR4/2layer_mu0.2_multi_Layer2_Network.txt.txt']\n",
    "_2layer_mu0_3_multi = ['mLFR4/2layer_mu0.3_multi_Layer1_Network.txt.txt', 'mLFR4/2layer_mu0.3_multi_Layer2_Network.txt.txt']\n",
    "_3layer_mu0_1_multi = ['mLFR4/3layer_mu0.1_multi_Layer1_Network.txt.txt', 'mLFR4/3layer_mu0.1_multi_Layer2_Network.txt.txt', 'mLFR4/3layer_mu0.1_multi_Layer3_Network.txt.txt']\n",
    "_3layer_mu0_2_multi = ['mLFR4/3layer_mu0.2_multi_Layer1_Network.txt.txt', 'mLFR4/3layer_mu0.2_multi_Layer2_Network.txt.txt', 'mLFR4/3layer_mu0.2_multi_Layer3_Network.txt.txt']\n",
    "_3layer_mu0_3_multi = ['mLFR4/3layer_mu0.3_multi_Layer1_Network.txt.txt', 'mLFR4/3layer_mu0.3_multi_Layer2_Network.txt.txt', 'mLFR4/3layer_mu0.3_multi_Layer3_Network.txt.txt']\n",
    "_3layer_mu0_4_multi = ['mLFR4/3layer_mu0.4_multi_Layer1_Network.txt.txt', 'mLFR4/3layer_mu0.4_multi_Layer2_Network.txt.txt', 'mLFR4/3layer_mu0.4_multi_Layer3_Network.txt.txt']\n",
    "_4layer_mu0_1_multi = ['mLFR4/4layer_mu0.1_multi_Layer1_Network.txt.txt', 'mLFR4/4layer_mu0.1_multi_Layer2_Network.txt.txt', 'mLFR4/4layer_mu0.1_multi_Layer3_Network.txt.txt', 'mLFR4/4layer_mu0.1_multi_Layer4_Network.txt.txt']\n",
    "_4layer_mu0_2_multi = ['mLFR4/4layer_mu0.2_multi_Layer1_Network.txt.txt', 'mLFR4/4layer_mu0.2_multi_Layer2_Network.txt.txt', 'mLFR4/4layer_mu0.2_multi_Layer3_Network.txt.txt', 'mLFR4/4layer_mu0.2_multi_Layer4_Network.txt.txt']\n",
    "_4layer_mu0_3_multi = ['mLFR4/4layer_mu0.3_multi_Layer1_Network.txt.txt', 'mLFR4/4layer_mu0.3_multi_Layer2_Network.txt.txt', 'mLFR4/4layer_mu0.3_multi_Layer3_Network.txt.txt', 'mLFR4/4layer_mu0.3_multi_Layer4_Network.txt.txt']\n",
    "_4layer_mu0_4_multi = ['mLFR4/4layer_mu0.4_multi_Layer1_Network.txt.txt', 'mLFR4/4layer_mu0.4_multi_Layer2_Network.txt.txt', 'mLFR4/4layer_mu0.4_multi_Layer4_Network.txt.txt', 'mLFR4/4layer_mu0.4_multi_Layer4_Network.txt.txt']\n",
    "\n",
    "testData = [_3layer_mu0_1_multi, _3layer_mu0_2_multi, _3layer_mu0_3_multi, _4layer_mu0_1_multi, _4layer_mu0_2_multi, _4layer_mu0_3_multi, _3layer_mu0_4_multi, _4layer_mu0_4_multi]\n",
    "# testData = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "time: 1.22 ms\n"
     ]
    }
   ],
   "source": [
    "%load_ext autotime\n",
    "\n",
    "import pygmo as pg\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "import community as comm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime, time, os\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.81 ms\n"
     ]
    }
   ],
   "source": [
    "class community_function:\n",
    "  def __init__(self, fileNames, alphaSemi=None, alphaPizz=None):\n",
    "    self.fileNames = fileNames\n",
    "    self.G = []\n",
    "    for fileName in self.fileNames:\n",
    "      g = self.getNeighbourMatrixFromFile(fileName)\n",
    "      self.G.append(g)\n",
    "    self.dim = len(list(self.G[0].nodes))\n",
    "    self.layers = len(fileNames)\n",
    "\n",
    "    if alphaPizz is None:\n",
    "      alphaPizz = 1\n",
    "    self.alphaPizz = alphaPizz\n",
    "    \n",
    "    self.H = []\n",
    "    for i in range(self.layers):\n",
    "      if alphaSemi is None:\n",
    "        self.alpha = np.full(self.layers, 0.5)\n",
    "      else:\n",
    "        self.alpha = np.full(self.layers, alphaSemi)\n",
    "      H = self.mergeLayers(i, self.alpha)\n",
    "      self.H.append(H)\n",
    "      \n",
    "  def fitness(self, x):\n",
    "    d = {}\n",
    "    x = np.asanyarray(x)\n",
    "    for val, ind in zip(np.nditer(x), np.ndindex(x.shape[0])):\n",
    "      d[ind[0]] = int(val)\n",
    "      \n",
    "    partitions = []\n",
    "    for partitionNumber in set(d.values()):\n",
    "      partition = []\n",
    "      for key in d:\n",
    "        if d[key] == partitionNumber:\n",
    "          partition.append(key)\n",
    "      partitions.append(partition)  \n",
    "    \n",
    "    f = 0\n",
    "    for g in self.H:\n",
    "      for partition in partitions:\n",
    "        k_out = 0\n",
    "        for node in partition:\n",
    "          for i in g.neighbors(node):\n",
    "            if i not in partition:\n",
    "              k_out += g[node][i]['weight']\n",
    "\n",
    "        k_in = 0\n",
    "        for node in partition:\n",
    "          for i in g.neighbors(node):\n",
    "            if i in partition:\n",
    "              k_in += g[node][i]['weight']\n",
    "        k_in = k_in//2\n",
    "        \n",
    "        if k_in + k_out != 0:\n",
    "          f += k_in/((k_in + k_out)**(self.alphaPizz))\n",
    "        else:\n",
    "          f += 0\n",
    "    \n",
    "    return [-f]\n",
    "\n",
    "  def get_bounds(self):\n",
    "    return ([1] * self.dim, [self.dim] * self.dim)\n",
    "  \n",
    "  def get_nix(self):\n",
    "    # Number of integer dimensions (all of them)\n",
    "    print(self.dim)\n",
    "    return self.dim\n",
    "  \n",
    "  def get_name(self):\n",
    "    ret = \"Best partition for multiplex graph\\n\"\n",
    "    for fileName in self.fileNames:\n",
    "      ret +=\"File: \" + fileName + \"\\n\"\n",
    "    ret += \"Dimension: \" + str(self.dim)\n",
    "    ret += \"\\n\\n\"\n",
    "    return ret\n",
    "  \n",
    "  def getNeighbourMatrixFromFile(self, fileName):\n",
    "    A = pd.read_csv(fileName, sep=\" \", header=None)\n",
    "    G = nx.from_numpy_matrix(np.array(A))\n",
    "    return G\n",
    "  \n",
    "  def drawPartition(self, graphIndex=0, partition=None, fun=nx.spring_layout, mergedDraw=False, fileNameEndsWith=\"_moeaGenerated.png\"):\n",
    "    if partition is None:\n",
    "      raise ValueError(\"No partition passed as parameter!!\")\n",
    "    if type(partition) is list:\n",
    "      partition = {key:val for key, val in enumerate(partition)}\n",
    "    if type(partition) is not dict:\n",
    "      raise ValueError(\"Invalid partititon as input: \" + str(type(partition)))\n",
    "\n",
    "    plt.clf()\n",
    "      \n",
    "    colors = self.getColors()\n",
    "    if not mergedDraw:\n",
    "      G = self.G[graphIndex]\n",
    "    else:\n",
    "      G = self.H[graphIndex]\n",
    "      for i in range(self.dim):\n",
    "        G.add_node(i)\n",
    "    pos = fun(G)\n",
    "    count = 0\n",
    "    \n",
    "    for com in set(partition.values()):\n",
    "      toDraw = True\n",
    "      list_nodes = [nodes for nodes in partition.keys() if partition[nodes] == com]\n",
    "      labels = dict()\n",
    "      for node in list_nodes:\n",
    "        labels[node] = node+1\n",
    "      node_colors = np.zeros((len(list_nodes), 3))\n",
    "      if mergedDraw:\n",
    "        try:\n",
    "          node_colors[:] = colors[count]\n",
    "          count += 1\n",
    "        except:\n",
    "          node_colors[:] = [1, 1, 1]\n",
    "      else:\n",
    "        if len(list_nodes) <= 3:\n",
    "          node_colors[:] = [1, 1, 1]\n",
    "          if fun != nx.circular_layout:\n",
    "            toDraw = False\n",
    "        else:\n",
    "          try:\n",
    "            node_colors[:] = colors[count]\n",
    "            count += 1\n",
    "          except:\n",
    "            node_colors[:] = [1, 1, 1]\n",
    "      if toDraw:\n",
    "        nx.draw_networkx_nodes(G, pos, list_nodes, node_size=20, node_color=node_colors)\n",
    "        nx.draw_networkx_labels(G, pos, labels, font_size=3)\n",
    "    nx.draw_networkx_edges(G, pos, width=0.2)\n",
    "    if mergedDraw:\n",
    "      labels = nx.get_edge_attributes(G,'weight')\n",
    "      nx.draw_networkx_edge_labels(G,pos,edge_labels=labels, font_size=3)\n",
    "    \n",
    "    if mergedDraw:\n",
    "      fileNameEndsWith = \"merged_view_\" + fileNameEndsWith\n",
    "    outfile=self.fileNames[graphIndex] + fileNameEndsWith\n",
    "    plt.savefig(outfile, dpi=300)\n",
    "    \n",
    "  def getColors(self):\n",
    "    return np.array([\n",
    "            [230, 25, 75],\n",
    "            [60, 180, 75],\n",
    "            [255, 225, 25],\n",
    "            [0, 130, 200],\n",
    "            [245, 130, 48],\n",
    "            [145, 30, 180],\n",
    "            [70, 240, 240],\n",
    "            [240, 50, 230],\n",
    "            [210, 245, 60],\n",
    "            [250, 190, 190],\n",
    "            [0, 128, 128],\n",
    "            [230, 190, 255],\n",
    "            [170, 110, 40],\n",
    "            [255, 250, 200],\n",
    "            [128, 0, 0],\n",
    "            [170, 255, 195],\n",
    "            [128, 128, 0],\n",
    "            [255, 215, 180],\n",
    "            [0, 0, 128],\n",
    "            [128, 128, 128],\n",
    "            [0, 0, 0]\n",
    "          ])/255\n",
    "  \n",
    "\n",
    "  def mergeLayers(self, mainLayer, alpha):\n",
    "    '''\n",
    "      Merge the layers into one graph but use alpha scaling for layers. The main layers scale is always 1\n",
    "      \n",
    "      mainLayer : integer\n",
    "                index of main layer\n",
    "      alpha : list\n",
    "    '''\n",
    "    alpha[mainLayer] = 1 #take the mainLayer's weights without scaling\n",
    "    H = nx.Graph()\n",
    "    for i in range(len(self.G)):\n",
    "      g = self.G[i]\n",
    "      for e in g.edges().data('weight'):\n",
    "        (u, v, weight) = e\n",
    "        if (u,v) not in H.edges():\n",
    "          H.add_edge(u,v, weight=weight*alpha[i])\n",
    "        else:\n",
    "          H[u][v]['weight'] = H[u][v]['weight'] + weight*alpha[i]\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 55, 43)\n",
      "\n",
      "3layermu0.1_semi_pizzuti_run\n",
      "128\n",
      "3layermu0.1_semi_pizzuti_run\n",
      "1\n",
      "3layermu0.1_semi_pizzuti_run\n",
      "2\n",
      "3layermu0.1_semi_pizzuti_run\n",
      "3\n",
      "3layermu0.1_semi_pizzuti_run\n",
      "4\n",
      "3layermu0.1_semi_pizzuti_run\n",
      "5\n",
      "3layermu0.1_semi_pizzuti_run\n",
      "6\n",
      "3layermu0.1_semi_pizzuti_run\n",
      "7\n",
      "3layermu0.1_semi_pizzuti_run\n",
      "8\n",
      "3layermu0.1_semi_pizzuti_run\n",
      "9\n",
      "3layermu0.1_semi_pizzuti_run\n",
      "10\n",
      "(22, 14, 14)\n",
      "\n",
      "time: 18min 31s\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for data in [testData[0]]:\n",
    "  now = datetime.datetime.now()\n",
    "  time_now = (now.hour, now.minute, now.second)\n",
    "  print(time_now)\n",
    "  print(\"\")\n",
    "  outFileName = ''.join(data[0].split('_')[0:2]).split('/')[1] + '_semi_pizzuti_run'\n",
    "  print(outFileName)\n",
    "\n",
    "  problem = pg.problem(community_function(data, alphaPizz=1))\n",
    "  algo = pg.algorithm(pg.sga(gen=4000))\n",
    "  algo.set_verbosity(100)\n",
    "  archi = pg.archipelago(n=10, algo=algo, prob=problem, pop_size=50)\n",
    "  archi.evolve()\n",
    "  archi.wait()\n",
    "  \n",
    "  for champion_x in archi.get_champions_x():\n",
    "    df = pd.DataFrame()\n",
    "    df[0] = list(range(0, len(champion_x)))\n",
    "    df[1] = champion_x.astype(int)\n",
    "\n",
    "    df.to_csv(outFileName + str(i) + '.txt', sep=' ', header=False, index=False)\n",
    "    i += 1\n",
    "  \n",
    "    print(outFileName)\n",
    "    print(i)\n",
    "  \n",
    "  now = datetime.datetime.now()\n",
    "  time_now = (now.hour, now.minute, now.second)\n",
    "  print(time_now)\n",
    "  print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
