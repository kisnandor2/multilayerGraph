{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import community as comm\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = '2layermu0.1_base.txt'\n",
    "# b2 = '2layermu0.1_all_community_merged_run1.txt'\n",
    "b = 'mLFR2/2layer_mu0.1_Community.txt'\n",
    "b2 = 'testComm.txt'\n",
    "base = pd.read_csv(b, sep=\" \", header=None)\n",
    "base = np.array(base[1].values)\n",
    "\n",
    "base2 = pd.read_csv(b2, sep=\" \", header=None)\n",
    "base2 = np.array(base2[1].values)\n",
    "\n",
    "graphs = ['mLFR2/2layer_mu0.1_Layer1_Network.txt.txt', 'mLFR2/2layer_mu0.1_Layer2_Network.txt.txt']\n",
    "A = pd.read_csv(graphs[0], sep=\" \", header=None)\n",
    "G1 = nx.from_numpy_matrix(np.array(A))\n",
    "\n",
    "A = pd.read_csv(graphs[1], sep=\" \", header=None)\n",
    "G2 = nx.from_numpy_matrix(np.array(A))\n",
    "\n",
    "# H1 = mergeLayers([G1, G2], 0, alpha = np.full(2, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41786242603550294"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.10615384615384615"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.6367455621301775"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 1,\n",
       " 2: 0,\n",
       " 3: 1,\n",
       " 4: 2,\n",
       " 5: 2,\n",
       " 6: 2,\n",
       " 7: 1,\n",
       " 8: 3,\n",
       " 9: 0,\n",
       " 10: 0,\n",
       " 11: 0,\n",
       " 12: 0,\n",
       " 13: 3,\n",
       " 14: 0,\n",
       " 15: 4,\n",
       " 16: 4,\n",
       " 17: 5,\n",
       " 18: 3,\n",
       " 19: 4,\n",
       " 20: 3,\n",
       " 21: 4,\n",
       " 22: 3,\n",
       " 23: 3,\n",
       " 24: 1,\n",
       " 25: 4,\n",
       " 26: 4,\n",
       " 27: 4,\n",
       " 28: 4,\n",
       " 29: 3,\n",
       " 30: 6,\n",
       " 31: 4,\n",
       " 32: 4,\n",
       " 33: 4,\n",
       " 34: 4,\n",
       " 35: 7,\n",
       " 36: 3,\n",
       " 37: 4,\n",
       " 38: 6,\n",
       " 39: 0,\n",
       " 40: 4,\n",
       " 41: 4,\n",
       " 42: 4,\n",
       " 43: 3,\n",
       " 44: 6,\n",
       " 45: 3,\n",
       " 46: 5,\n",
       " 47: 3,\n",
       " 48: 3,\n",
       " 49: 8,\n",
       " 50: 1,\n",
       " 51: 7,\n",
       " 52: 6,\n",
       " 53: 6,\n",
       " 54: 0,\n",
       " 55: 0,\n",
       " 56: 0,\n",
       " 57: 7,\n",
       " 58: 0,\n",
       " 59: 6,\n",
       " 60: 8,\n",
       " 61: 7,\n",
       " 62: 0,\n",
       " 63: 6,\n",
       " 64: 7,\n",
       " 65: 8,\n",
       " 66: 6,\n",
       " 67: 0,\n",
       " 68: 6,\n",
       " 69: 0,\n",
       " 70: 7,\n",
       " 71: 0,\n",
       " 72: 7,\n",
       " 73: 7,\n",
       " 74: 8,\n",
       " 75: 6,\n",
       " 76: 5,\n",
       " 77: 5,\n",
       " 78: 7,\n",
       " 79: 7,\n",
       " 80: 1,\n",
       " 81: 7,\n",
       " 82: 8,\n",
       " 83: 8,\n",
       " 84: 7,\n",
       " 85: 7,\n",
       " 86: 5,\n",
       " 87: 7,\n",
       " 88: 5,\n",
       " 89: 0,\n",
       " 90: 8,\n",
       " 91: 5,\n",
       " 92: 1,\n",
       " 93: 7,\n",
       " 94: 1,\n",
       " 95: 7,\n",
       " 96: 1,\n",
       " 97: 5,\n",
       " 98: 1,\n",
       " 99: 5,\n",
       " 100: 1,\n",
       " 101: 7,\n",
       " 102: 7,\n",
       " 103: 1,\n",
       " 104: 5,\n",
       " 105: 1,\n",
       " 106: 7,\n",
       " 107: 5,\n",
       " 108: 7,\n",
       " 109: 1,\n",
       " 110: 7,\n",
       " 111: 7,\n",
       " 112: 7,\n",
       " 113: 1,\n",
       " 114: 1,\n",
       " 115: 1,\n",
       " 116: 7,\n",
       " 117: 7,\n",
       " 118: 1,\n",
       " 119: 1,\n",
       " 120: 1,\n",
       " 121: 7,\n",
       " 122: 1,\n",
       " 123: 7,\n",
       " 124: 1,\n",
       " 125: 1,\n",
       " 126: 7,\n",
       " 127: 7}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G1 = G2\n",
    "partition = {}\n",
    "x = base\n",
    "for val, ind in zip(np.nditer(x), np.ndindex(x.shape[0])):\n",
    "  partition[ind[0]] = int(val)\n",
    "  \n",
    "comm.modularity(partition, G1)\n",
    "\n",
    "partition = {}\n",
    "x = base2\n",
    "for val, ind in zip(np.nditer(x), np.ndindex(x.shape[0])):\n",
    "  partition[ind[0]] = int(val)\n",
    "  \n",
    "comm.modularity(partition, G1)\n",
    "\n",
    "partition = comm.best_partition(G1)\n",
    "comm.modularity(partition, G1)\n",
    "partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.3753569139327545\n",
      "0.34402366863905315\n",
      "\n",
      "0.1\n",
      "0.37252917631172816\n",
      "0.3468930212070642\n",
      "\n",
      "0.2\n",
      "0.37016958091606217\n",
      "0.34928093763371815\n",
      "\n",
      "0.30000000000000004\n",
      "0.3681707612456742\n",
      "0.35129920673325954\n",
      "\n",
      "0.4\n",
      "0.3664558511750133\n",
      "0.35302749403662737\n",
      "\n",
      "0.5\n",
      "0.36496837255310294\n",
      "0.35452410698517156\n",
      "\n",
      "0.6000000000000001\n",
      "0.36366589592729026\n",
      "0.3558327028843151\n",
      "\n",
      "0.7000000000000001\n",
      "0.3625159280902523\n",
      "0.35698661814669064\n",
      "\n",
      "0.8\n",
      "0.3614931643277503\n",
      "0.35801174800983276\n",
      "\n",
      "0.9\n",
      "0.3605776047086376\n",
      "0.3589285130229065\n",
      "\n",
      "1.0\n",
      "0.35975323321736324\n",
      "0.35975323321736324\n",
      "\n",
      "1.1\n",
      "0.35900707283286193\n",
      "0.3604991081554951\n",
      "\n",
      "1.2000000000000002\n",
      "0.3583284973715836\n",
      "0.3611769287171882\n",
      "\n",
      "1.3\n",
      "0.35770872222222255\n",
      "0.36179560255484383\n",
      "\n",
      "1.4000000000000001\n",
      "0.35714042197021584\n",
      "0.3623625477450731\n",
      "\n",
      "1.5\n",
      "0.3566174394971583\n",
      "0.36288399166058877\n",
      "\n",
      "1.6\n",
      "0.3561345620034629\n",
      "0.3633652006587112\n",
      "\n",
      "1.7000000000000002\n",
      "0.3556873466554747\n",
      "0.36381065857624334\n",
      "\n",
      "1.8\n",
      "0.3552719834865835\n",
      "0.36422420686581386\n",
      "\n",
      "1.9000000000000001\n",
      "0.3548851865849223\n",
      "0.36460915565825475\n",
      "\n",
      "2.0\n",
      "0.35452410698517156\n",
      "0.36496837255310294\n",
      "\n",
      "1.0\n",
      "0.7195064664347265\n"
     ]
    }
   ],
   "source": [
    "_max = 0\n",
    "t = 0\n",
    "partition = {}\n",
    "x = base\n",
    "for val, ind in zip(np.nditer(x), np.ndindex(x.shape[0])):\n",
    "  partition[ind[0]] = int(val)\n",
    "\n",
    "for i in np.arange(0,2.1,0.1):\n",
    "  alpha = np.full(2, i)\n",
    "  H1 = mergeLayers([G1, G2], 0, alpha)\n",
    "  alpha = np.full(2, i)\n",
    "  H2 = mergeLayers([G1, G2], 1, alpha)\n",
    "  \n",
    "  print(i)\n",
    "  m = comm.modularity(partition, H1, weight='weight')\n",
    "  \n",
    "  print(m)\n",
    "  m += comm.modularity(partition, H2, weight='weight')\n",
    "  print(comm.modularity(partition, H2, weight='weight'))\n",
    "  if m > _max:\n",
    "    _max = m\n",
    "    t = i\n",
    "  print()\n",
    "print(t)\n",
    "print(_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeLayers(G, mainLayer, alpha):\n",
    "  alpha[mainLayer] = 1 #take the mainLayer's weights without scaling\n",
    "  H = nx.Graph()\n",
    "  for i in range(len(G)):\n",
    "    g = G[i]\n",
    "    for e in g.edges().data('weight'):\n",
    "      (u, v, weight) = e\n",
    "      if (u,v) not in H.edges():\n",
    "        H.add_edge(u,v, weight=weight*alpha[i])\n",
    "      else:\n",
    "        H[u][v]['weight'] = H[u][v]['weight'] + weight*alpha[i]\n",
    "#   print(H.edges.data())\n",
    "  return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n",
      "qq: nan\n",
      "\n",
      "0.0\n",
      "-2.7755575615628914e-16\n",
      "qq: -2.7755575615628914e-16\n",
      "\n",
      "0.0\n",
      "-2.7755575615628914e-16\n",
      "qq: -2.7755575615628914e-16\n",
      "\n",
      "0.0\n",
      "2.0045693500176435e-16\n",
      "qq: 2.0045693500176435e-16\n",
      "\n",
      "0.0\n",
      "-2.7755575615628914e-16\n",
      "qq: -2.7755575615628914e-16\n",
      "\n",
      "0.0\n",
      "1.942890293094024e-16\n",
      "qq: 1.942890293094024e-16\n",
      "\n",
      "0.0\n",
      "2.0045693500176435e-16\n",
      "qq: 2.0045693500176435e-16\n",
      "\n",
      "0.0\n",
      "-8.591011500075615e-17\n",
      "qq: -8.591011500075615e-17\n",
      "\n",
      "0.0\n",
      "-2.7755575615628914e-16\n",
      "qq: -2.7755575615628914e-16\n",
      "\n",
      "0.0\n",
      "1.953170135914627e-16\n",
      "qq: 1.953170135914627e-16\n",
      "\n",
      "0.0\n",
      "1.942890293094024e-16\n",
      "qq: 1.942890293094024e-16\n",
      "\n",
      "-0.013888888888888838\n",
      "0.0\n",
      "qq: -0.013888888888888838\n",
      "\n",
      "0.3641975308641975\n",
      "0.5\n",
      "qq: 0.8641975308641975\n",
      "\n",
      "0.4131944444444444\n",
      "0.44444444444444425\n",
      "qq: 0.8576388888888886\n",
      "\n",
      "0.3977777777777778\n",
      "0.37500000000000006\n",
      "qq: 0.7727777777777778\n",
      "\n",
      "0.36882716049382724\n",
      "0.31999999999999984\n",
      "qq: 0.6888271604938271\n",
      "\n",
      "0.3390022675736962\n",
      "0.2777777777777781\n",
      "qq: 0.6167800453514743\n",
      "\n",
      "0.3116319444444445\n",
      "0.24489795918367366\n",
      "qq: 0.5565299036281182\n",
      "\n",
      "0.2873799725651577\n",
      "0.21874999999999994\n",
      "qq: 0.5061299725651576\n",
      "\n",
      "0.2661111111111111\n",
      "0.19753086419753077\n",
      "qq: 0.4636419753086418\n",
      "\n",
      "0.2474747474747475\n",
      "0.18000000000000027\n",
      "qq: 0.4274747474747478\n",
      "\n",
      "0.2310956790123457\n",
      "0.1652892561983474\n",
      "qq: 0.39638493521069307\n",
      "\n",
      "-0.013888888888888838\n",
      "0.0\n",
      "qq: -0.013888888888888838\n",
      "\n",
      "0.2577777777777777\n",
      "0.44444444444444453\n",
      "qq: 0.7022222222222223\n",
      "\n",
      "0.3641975308641975\n",
      "0.5\n",
      "qq: 0.8641975308641975\n",
      "\n",
      "0.40362811791383224\n",
      "0.4799999999999998\n",
      "qq: 0.8836281179138321\n",
      "\n",
      "0.4131944444444444\n",
      "0.44444444444444425\n",
      "qq: 0.8576388888888886\n",
      "\n",
      "0.4087791495198902\n",
      "0.40816326530612235\n",
      "qq: 0.8169424148260125\n",
      "\n",
      "0.3977777777777778\n",
      "0.37500000000000006\n",
      "qq: 0.7727777777777778\n",
      "\n",
      "0.3838383838383838\n",
      "0.34567901234567927\n",
      "qq: 0.7295173961840631\n",
      "\n",
      "0.36882716049382724\n",
      "0.31999999999999984\n",
      "qq: 0.6888271604938271\n",
      "\n",
      "0.3537146614069691\n",
      "0.29752066115702486\n",
      "qq: 0.651235322563994\n",
      "\n",
      "0.3390022675736962\n",
      "0.2777777777777781\n",
      "qq: 0.6167800453514743\n",
      "\n",
      "-0.013888888888888807\n",
      "0.0\n",
      "qq: -0.013888888888888807\n",
      "\n",
      "0.19387755102040805\n",
      "0.37499999999999994\n",
      "qq: 0.568877551020408\n",
      "\n",
      "0.30468749999999994\n",
      "0.48\n",
      "qq: 0.7846875\n",
      "\n",
      "0.36419753086419754\n",
      "0.5\n",
      "qq: 0.8641975308641976\n",
      "\n",
      "0.39499999999999985\n",
      "0.48979591836734687\n",
      "qq: 0.8847959183673467\n",
      "\n",
      "0.40909090909090906\n",
      "0.46875\n",
      "qq: 0.8778409090909091\n",
      "\n",
      "0.4131944444444444\n",
      "0.4444444444444445\n",
      "qq: 0.8576388888888888\n",
      "\n",
      "0.4112426035502958\n",
      "0.42\n",
      "qq: 0.8312426035502958\n",
      "\n",
      "0.40561224489795916\n",
      "0.3966942148760329\n",
      "qq: 0.8023064597739921\n",
      "\n",
      "0.39777777777777773\n",
      "0.375\n",
      "qq: 0.7727777777777778\n",
      "\n",
      "0.38867187500000006\n",
      "0.3550295857988166\n",
      "qq: 0.7437014607988166\n",
      "\n",
      "-0.013888888888888838\n",
      "0.0\n",
      "qq: -0.013888888888888838\n",
      "\n",
      "0.15363511659807938\n",
      "0.31999999999999995\n",
      "qq: 0.47363511659807933\n",
      "\n",
      "0.2577777777777777\n",
      "0.44444444444444453\n",
      "qq: 0.7022222222222223\n",
      "\n",
      "0.323232323232323\n",
      "0.489795918367347\n",
      "qq: 0.8130282415996699\n",
      "\n",
      "0.3641975308641975\n",
      "0.5\n",
      "qq: 0.8641975308641975\n",
      "\n",
      "0.3892176199868507\n",
      "0.4938271604938272\n",
      "qq: 0.8830447804806779\n",
      "\n",
      "0.40362811791383224\n",
      "0.4799999999999998\n",
      "qq: 0.8836281179138321\n",
      "\n",
      "0.4108641975308641\n",
      "0.46280991735537186\n",
      "qq: 0.8736741148862359\n",
      "\n",
      "0.4131944444444444\n",
      "0.44444444444444425\n",
      "qq: 0.8576388888888886\n",
      "\n",
      "0.412149173394848\n",
      "0.4260355029585798\n",
      "qq: 0.8381846763534277\n",
      "\n",
      "0.4087791495198902\n",
      "0.40816326530612235\n",
      "qq: 0.8169424148260125\n",
      "\n",
      "-0.013888888888888859\n",
      "0.0\n",
      "qq: -0.013888888888888859\n",
      "\n",
      "0.12626262626262635\n",
      "0.2777777777777778\n",
      "qq: 0.40404040404040414\n",
      "\n",
      "0.22183641975308657\n",
      "0.40816326530612246\n",
      "qq: 0.629999685059209\n",
      "\n",
      "0.28763971071663375\n",
      "0.46875\n",
      "qq: 0.7563897107166337\n",
      "\n",
      "0.3330498866213151\n",
      "0.493827160493827\n",
      "qq: 0.8268770471151421\n",
      "\n",
      "0.3641975308641976\n",
      "0.5000000000000001\n",
      "qq: 0.8641975308641977\n",
      "\n",
      "0.38519965277777773\n",
      "0.49586776859504134\n",
      "qq: 0.8810674213728191\n",
      "\n",
      "0.398885044213764\n",
      "0.4861111111111111\n",
      "qq: 0.8849961553248751\n",
      "\n",
      "0.40723593964334714\n",
      "0.47337278106508857\n",
      "qq: 0.8806087207084357\n",
      "\n",
      "0.4116651277316098\n",
      "0.4591836734693877\n",
      "qq: 0.8708488012009975\n",
      "\n",
      "0.4131944444444444\n",
      "0.4444444444444444\n",
      "qq: 0.8576388888888888\n",
      "\n",
      "-0.013888888888888807\n",
      "0.0\n",
      "qq: -0.013888888888888807\n",
      "\n",
      "0.10650887573964486\n",
      "0.24489795918367344\n",
      "qq: 0.3514068349233183\n",
      "\n",
      "0.19387755102040805\n",
      "0.37499999999999994\n",
      "qq: 0.568877551020408\n",
      "\n",
      "0.2577777777777777\n",
      "0.4444444444444445\n",
      "qq: 0.7022222222222222\n",
      "\n",
      "0.30468749999999994\n",
      "0.48\n",
      "qq: 0.7846875\n",
      "\n",
      "0.3391003460207613\n",
      "0.4958677685950415\n",
      "qq: 0.8349681146158028\n",
      "\n",
      "0.36419753086419754\n",
      "0.5\n",
      "qq: 0.8641975308641976\n",
      "\n",
      "0.38227146814404434\n",
      "0.4970414201183431\n",
      "qq: 0.8793128882623875\n",
      "\n",
      "0.39499999999999985\n",
      "0.48979591836734687\n",
      "qq: 0.8847959183673467\n",
      "\n",
      "0.4036281179138321\n",
      "0.4799999999999999\n",
      "qq: 0.883628117913832\n",
      "\n",
      "0.40909090909090906\n",
      "0.46875\n",
      "qq: 0.8778409090909091\n",
      "\n",
      "-0.013888888888888892\n",
      "0.0\n",
      "qq: -0.013888888888888892\n",
      "\n",
      "0.09160493827160485\n",
      "0.21874999999999997\n",
      "qq: 0.3103549382716048\n",
      "\n",
      "0.17165798611111108\n",
      "0.345679012345679\n",
      "qq: 0.51733699845679\n",
      "\n",
      "0.23279507881584013\n",
      "0.42000000000000004\n",
      "qq: 0.6527950788158402\n",
      "\n",
      "0.2796639231824418\n",
      "0.46280991735537197\n",
      "qq: 0.7424738405378137\n",
      "\n",
      "0.3156355801785165\n",
      "0.4861111111111111\n",
      "qq: 0.8017466912896276\n",
      "\n",
      "0.3431944444444444\n",
      "0.4970414201183432\n",
      "qq: 0.8402358645627876\n",
      "\n",
      "0.3641975308641976\n",
      "0.5000000000000001\n",
      "qq: 0.8641975308641977\n",
      "\n",
      "0.38005050505050497\n",
      "0.49777777777777765\n",
      "qq: 0.8778282828282826\n",
      "\n",
      "0.39182944759504307\n",
      "0.4921874999999999\n",
      "qq: 0.884016947595043\n",
      "\n",
      "0.40036651234567905\n",
      "0.4844290657439447\n",
      "qq: 0.8847955780896237\n",
      "\n",
      "-0.013888888888888838\n",
      "0.0\n",
      "qq: -0.013888888888888838\n",
      "\n",
      "0.0799692425990001\n",
      "0.19753086419753085\n",
      "qq: 0.2775001067965309\n",
      "\n",
      "0.15363511659807938\n",
      "0.31999999999999995\n",
      "qq: 0.47363511659807933\n",
      "\n",
      "0.21175746383502608\n",
      "0.396694214876033\n",
      "qq: 0.6084516787110591\n",
      "\n",
      "0.2577777777777777\n",
      "0.44444444444444453\n",
      "qq: 0.7022222222222223\n",
      "\n",
      "0.2942806752330561\n",
      "0.4733727810650888\n",
      "qq: 0.767653456298145\n",
      "\n",
      "0.323232323232323\n",
      "0.489795918367347\n",
      "qq: 0.8130282415996699\n",
      "\n",
      "0.34614576769586214\n",
      "0.4977777777777777\n",
      "qq: 0.8439235454736398\n",
      "\n",
      "0.3641975308641975\n",
      "0.5\n",
      "qq: 0.8641975308641975\n",
      "\n",
      "0.3783111111111111\n",
      "0.49826989619377154\n",
      "qq: 0.8765810073048826\n",
      "\n",
      "0.3892176199868507\n",
      "0.4938271604938272\n",
      "qq: 0.8830447804806779\n",
      "\n",
      "-0.013888888888888848\n",
      "0.0\n",
      "qq: -0.013888888888888848\n",
      "\n",
      "0.07063711911357314\n",
      "0.18000000000000002\n",
      "qq: 0.25063711911357317\n",
      "\n",
      "0.13875000000000012\n",
      "0.2975206611570248\n",
      "qq: 0.43627066115702495\n",
      "\n",
      "0.19387755102040807\n",
      "0.3750000000000001\n",
      "qq: 0.5688775510204082\n",
      "\n",
      "0.23863636363636384\n",
      "0.4260355029585799\n",
      "qq: 0.6646718665949437\n",
      "\n",
      "0.27504725897920596\n",
      "0.45918367346938777\n",
      "qq: 0.7342309324485937\n",
      "\n",
      "0.30468749999999994\n",
      "0.4799999999999999\n",
      "qq: 0.7846874999999999\n",
      "\n",
      "0.3288\n",
      "0.4921874999999999\n",
      "qq: 0.8209874999999999\n",
      "\n",
      "0.3483727810650888\n",
      "0.49826989619377154\n",
      "qq: 0.8466426772588603\n",
      "\n",
      "0.36419753086419754\n",
      "0.5\n",
      "qq: 0.8641975308641976\n",
      "\n",
      "0.3769132653061224\n",
      "0.49861495844875353\n",
      "qq: 0.8755282237548759\n",
      "\n",
      "-0.013888888888888859\n",
      "0.0\n",
      "qq: -0.013888888888888859\n",
      "\n",
      "0.06298815822625324\n",
      "0.16528925619834714\n",
      "qq: 0.22827741442460037\n",
      "\n",
      "0.12626262626262635\n",
      "0.2777777777777778\n",
      "qq: 0.40404040404040414\n",
      "\n",
      "0.17853392144507454\n",
      "0.35502958579881666\n",
      "qq: 0.5335635072438912\n",
      "\n",
      "0.22183641975308657\n",
      "0.40816326530612246\n",
      "qq: 0.629999685059209\n",
      "\n",
      "0.25777777777777783\n",
      "0.4444444444444444\n",
      "qq: 0.7022222222222223\n",
      "\n",
      "0.28763971071663375\n",
      "0.46875\n",
      "qq: 0.7563897107166337\n",
      "\n",
      "0.3124523700655387\n",
      "0.4844290657439446\n",
      "qq: 0.7968814358094833\n",
      "\n",
      "0.3330498866213151\n",
      "0.493827160493827\n",
      "qq: 0.8268770471151421\n",
      "\n",
      "0.35011230017175327\n",
      "0.4986149584487534\n",
      "qq: 0.8487272586205067\n",
      "\n",
      "0.3641975308641976\n",
      "0.5000000000000001\n",
      "qq: 0.8641975308641977\n",
      "\n",
      "\n",
      "0.5 0.7000000000000001 0.8849961553248751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kisnandor2/.local/lib/python3.6/site-packages/ipykernel_launcher.py:27: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/kisnandor2/.local/lib/python3.6/site-packages/ipykernel_launcher.py:52: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "_max = 0\n",
    "(oo, tt) = (None, None)\n",
    "for (o, t) in [(o,t) for o in np.arange(0,1.1,0.1) for t in np.arange(0,1.1,0.1)]:\n",
    "  A = np.zeros((7,7))\n",
    "\n",
    "  A[0,1] = A[1,0] = o\n",
    "  A[0,2] = A[2,0] = o\n",
    "  A[0,3] = A[3,0] = o\n",
    "  A[1,2] = A[2,1] = o\n",
    "  A[2,3] = A[3,2] = o\n",
    "  A[2,4] = A[4,2] = o\n",
    "\n",
    "  # A[1,3] = A[3,1] = 1\n",
    "\n",
    "  A[4,5] = A[5,4] = t\n",
    "  A[4,6] = A[6,4] = t\n",
    "  A[5,6] = A[6,5] = t\n",
    "\n",
    "  k = np.sum(A,1)\n",
    "  m = sum(k)/2\n",
    "\n",
    "  s = [1,1,1,1,0,0,0]\n",
    "\n",
    "  q = 0\n",
    "  for i in range(0,7):\n",
    "    for j in range(0,7):\n",
    "      q += (A[i,j] - (k[i]*k[j])/(2*m)) * (s[i]*s[j])\n",
    "      \n",
    "  qq = q/m    \n",
    "  print(q/m)\n",
    "  # Layer 2\n",
    "  A = np.zeros((7,7))\n",
    "\n",
    "  A[0,3] = A[3,0] = t\n",
    "  A[1,2] = A[2,1] = t\n",
    "  A[0,2] = A[2,0] = t\n",
    "  \n",
    "  # A[1,3] = A[3,1] = 1\n",
    "\n",
    "  A[4,5] = A[5,4] = o\n",
    "  A[4,6] = A[6,4] = o\n",
    "  A[5,6] = A[6,5] = o\n",
    "\n",
    "  k = np.sum(A,1)\n",
    "  m = sum(k)/2\n",
    "\n",
    "  s = [1,1,1,1,0,0,0]\n",
    "\n",
    "  q = 0\n",
    "  for i in range(0,7):\n",
    "    for j in range(0,7):\n",
    "      q += (A[i,j] - (k[i]*k[j])/(2*m)) * (s[i]*s[j])\n",
    "  print(q/m)\n",
    "  qq += q/m\n",
    "  print(\"qq: \" + str(qq))\n",
    "  print(\"\")\n",
    "  if qq > _max:\n",
    "    (oo, tt) = (o, t)\n",
    "    _max = qq\n",
    "print(\"\")\n",
    "print(oo, tt, _max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.013888888888888753"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = nx.from_numpy_matrix(A)\n",
    "partition = {}\n",
    "x = np.array(s)\n",
    "for val, ind in zip(np.nditer(x), np.ndindex(x.shape[0])):\n",
    "  partition[ind[0]] = int(val)\n",
    "  \n",
    "comm.modularity(partition, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7483482335058627"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.zeros((7,7))\n",
    "\n",
    "o = 1\n",
    "t = 0.5\n",
    "A[0,1] = A[1,0] = o\n",
    "A[0,2] = A[2,0] = o\n",
    "A[0,3] = A[3,0] = o\n",
    "A[1,2] = A[2,1] = o\n",
    "A[2,3] = A[3,2] = o\n",
    "A[2,4] = A[4,2] = o\n",
    "\n",
    "# A[1,3] = A[3,1] = 1\n",
    "\n",
    "A[4,5] = A[5,4] = t\n",
    "A[4,6] = A[6,4] = t\n",
    "A[5,6] = A[6,5] = t\n",
    "\n",
    "k = np.sum(A,1)\n",
    "m = sum(k)/2\n",
    "\n",
    "s = [1,1,1,1,0,0,0]\n",
    "\n",
    "g = nx.from_numpy_matrix(A)\n",
    "\n",
    "pizzutiFitness(g, np.array(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pizzutiFitness(g, x, alpha=1):\n",
    "  \n",
    "  _max = 0\n",
    "  for node in g.nodes():\n",
    "    for i in g[node]:\n",
    "      if g[node][i]['weight'] > _max:\n",
    "        _max = g[node][i]['weight']\n",
    "  _max\n",
    "  \n",
    "  d = {}\n",
    "  for val, ind in zip(np.nditer(x), np.ndindex(x.shape[0])):\n",
    "    d[ind[0]] = int(val)\n",
    "\n",
    "  partitions = []\n",
    "  for partitionNumber in set(d.values()):\n",
    "    partition = []\n",
    "    for key in d:\n",
    "      if d[key] == partitionNumber:\n",
    "        partition.append(key)\n",
    "    partitions.append(partition)  \n",
    "\n",
    "  fitness = 0\n",
    "\n",
    "  for partition in partitions:\n",
    "    k_out = 0\n",
    "    for node in partition:\n",
    "      for i, datas in g[node].items():\n",
    "        if i not in partition:\n",
    "          k_out += datas.get('weight', 1)/_max\n",
    "\n",
    "    k_in = 0\n",
    "    for node in partition:\n",
    "      for i, datas in g[node].items():\n",
    "        if i in partition:\n",
    "          k_in += datas.get('weight', 1)/_max\n",
    "    k_in = k_in//2\n",
    "\n",
    "    fitness += k_in/((k_in + k_out)**(alpha))\n",
    "  \n",
    "  return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "3.8017594933087553\n",
      "6.840591431870486\n",
      "\n",
      "0.02\n",
      "3.806196610748315\n",
      "6.81384871241122\n",
      "\n",
      "0.03\n",
      "3.810575251346661\n",
      "6.770099066076245\n",
      "\n",
      "0.04\n",
      "3.374420409490366\n",
      "6.395343589746449\n",
      "\n",
      "0.05\n",
      "3.7120189515764923\n",
      "6.689380529806563\n",
      "\n",
      "0.060000000000000005\n",
      "3.823371998119782\n",
      "6.211556082686219\n",
      "\n",
      "0.06999999999999999\n",
      "3.827528258191085\n",
      "6.616475055448835\n",
      "\n",
      "0.08\n",
      "3.3911554590467037\n",
      "6.142093124004032\n",
      "\n",
      "0.09\n",
      "3.8356832042843787\n",
      "6.109714367169998\n",
      "\n",
      "0.09999999999999999\n",
      "3.8396839271948116\n",
      "6.519227308433781\n",
      "\n",
      "0.11\n",
      "3.4031586059775183\n",
      "6.049103195835885\n",
      "\n",
      "0.12\n",
      "3.4949369486160773\n",
      "6.354013600704599\n",
      "\n",
      "0.13\n",
      "3.8605056041000307\n",
      "6.425459131454145\n",
      "\n",
      "0.14\n",
      "3.8643228759346\n",
      "6.399255293008633\n",
      "\n",
      "0.15000000000000002\n",
      "3.8718633685850334\n",
      "6.371054805245988\n",
      "\n",
      "0.16\n",
      "3.8755864169020056\n",
      "6.346787281848297\n",
      "\n",
      "0.17\n",
      "3.8792648346926764\n",
      "6.32340365910927\n",
      "\n",
      "0.18000000000000002\n",
      "3.8828994410476523\n",
      "6.300852340922697\n",
      "\n",
      "0.19\n",
      "3.8864910346252883\n",
      "6.279085918802528\n",
      "\n",
      "0.01\n",
      "10.64235092517924\n"
     ]
    }
   ],
   "source": [
    "_max = 0\n",
    "t = 0\n",
    "partition = {}\n",
    "\n",
    "for i in np.arange(0.01,0.2,0.01):\n",
    "  alpha = np.full(2, i)\n",
    "  H1 = mergeLayers([G1, G2], 0, alpha)\n",
    "  alpha = np.full(2, i)\n",
    "  H2 = mergeLayers([G1, G2], 1, alpha)\n",
    "  \n",
    "  print(i)\n",
    "  m = pizzutiFitness(H1, np.array(base))\n",
    "  \n",
    "  print(m)\n",
    "  m += pizzutiFitness(H2, np.array(base))\n",
    "  print(pizzutiFitness(H2, np.array(base)))\n",
    "  if m > _max:\n",
    "    _max = m\n",
    "    t = i\n",
    "  print()\n",
    "print(t)\n",
    "print(_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 1, 1, 1]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def numberToBase(n, b):\n",
    "    if n == 0:\n",
    "        return [0]\n",
    "    digits = []\n",
    "    while n:\n",
    "        digits.append(int(n % b))\n",
    "        n //= b\n",
    "    return digits[::-1]\n",
    "\n",
    "_max = 0\n",
    "saved = []\n",
    "for i in range(0, 823542+1):\n",
    "  n = numberToBase(i, 7)\n",
    "  while len(n) < 7:\n",
    "    n = np.insert(n, 0, [0])\n",
    "  x = np.array(n)\n",
    "  for val, ind in zip(np.nditer(x), np.ndindex(x.shape[0])):\n",
    "    partition[ind[0]] = int(val)\n",
    "  \n",
    "  m = comm.modularity(partition, g)\n",
    "  if m > _max:\n",
    "    saved = list(n)\n",
    "    _max = m\n",
    "saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3641975308641975"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.12345679012345673"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.zeros((7,7))\n",
    "o = t = 1\n",
    "A[0,1] = A[1,0] = o\n",
    "A[0,2] = A[2,0] = o\n",
    "A[0,3] = A[3,0] = o\n",
    "A[1,2] = A[2,1] = o\n",
    "A[2,3] = A[3,2] = o\n",
    "A[2,4] = A[4,2] = o\n",
    "\n",
    "# A[1,3] = A[3,1] = 1\n",
    "\n",
    "A[4,5] = A[5,4] = t\n",
    "A[4,6] = A[6,4] = t\n",
    "A[5,6] = A[6,5] = t\n",
    "\n",
    "k = np.sum(A,1)\n",
    "m = sum(k)/2\n",
    "\n",
    "s = [1,1,1,1,0,0,0]\n",
    "\n",
    "g = nx.from_numpy_matrix(A)\n",
    "\n",
    "\n",
    "# for i in range(0,7):\n",
    "#   ss = np.zeros((7))\n",
    "#   for j in range(0,7):\n",
    "#     for k in range(0,7):\n",
    "#       ss[i] = j\n",
    "#       print(ss)\n",
    "  \n",
    "\n",
    "partition = {}\n",
    "x = np.array(s)\n",
    "for val, ind in zip(np.nditer(x), np.ndindex(x.shape[0])):\n",
    "  partition[ind[0]] = int(val)\n",
    "  \n",
    "comm.modularity(partition, g)\n",
    "\n",
    "s = [6, 6, 6, 6, 6, 5, 5]\n",
    "\n",
    "partition = {}\n",
    "x = np.array(s)\n",
    "for val, ind in zip(np.nditer(x), np.ndindex(x.shape[0])):\n",
    "  partition[ind[0]] = int(val)\n",
    "  \n",
    "comm.modularity(partition, g)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
